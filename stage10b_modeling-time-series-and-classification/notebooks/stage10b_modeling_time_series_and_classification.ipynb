{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0014afa0",
   "metadata": {},
   "source": [
    "# Stage 10b — Modeling: Time Series & Classification\n",
    "\n",
    "This notebook creates **lag/rolling features** on a synthetic time series and trains a **classifier** to predict next‑step direction. It follows the assignment: Data → Features → Target → Split → Pipeline → Metrics → Interpretation.\n",
    "\n",
    "**Tip:** Replace the synthetic generator with your dataset loader to adapt this baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659469e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from src.utils import project_path, save_df, classification_report_df, plot_confusion_matrix\n",
    "\n",
    "# Plot config\n",
    "plt.rcParams['figure.figsize'] = (8,4)\n",
    "plt.rcParams['axes.grid'] = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd59113",
   "metadata": {},
   "source": [
    "## 1) Data\n",
    "We simulate a daily return series with mild autocorrelation (AR(1) + noise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8835af21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic daily returns (AR(1))\n",
    "rng = np.random.default_rng(7)\n",
    "n = 1500\n",
    "phi = 0.15   # AR(1) coefficient\n",
    "eps = rng.normal(0, 0.01, size=n)\n",
    "ret = np.zeros(n)\n",
    "for t in range(1, n):\n",
    "    ret[t] = phi * ret[t-1] + eps[t]\n",
    "\n",
    "dates = pd.date_range('2015-01-01', periods=n, freq='B')  # business days\n",
    "df = pd.DataFrame({'ret': ret}, index=dates)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6319f4e",
   "metadata": {},
   "source": [
    "## 2) Features (leakage‑safe)\n",
    "We create several features using only **past** information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee12c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(d: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = d.copy()\n",
    "    # Lags\n",
    "    out['lag_1'] = out['ret'].shift(1)\n",
    "    out['lag_5'] = out['ret'].shift(5)\n",
    "    # Rolling stats (window=5)\n",
    "    out['roll_mean_5'] = out['ret'].shift(1).rolling(5).mean()   # shift(1) to avoid leakage\n",
    "    out['roll_std_5']  = out['ret'].shift(1).rolling(5).std()\n",
    "    # Momentum over 5 days\n",
    "    out['momentum_5'] = out['ret'].shift(1) - out['ret'].shift(6)\n",
    "    # Z-score over a 5-day window\n",
    "    mu = out['ret'].shift(1).rolling(5).mean()\n",
    "    sd = out['ret'].shift(1).rolling(5).std()\n",
    "    out['zscore_5'] = (out['ret'].shift(1) - mu) / sd\n",
    "    return out\n",
    "\n",
    "df_feat = make_features(df)\n",
    "df_feat.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376fdad8",
   "metadata": {},
   "source": [
    "## 3) Target\n",
    "Binary direction for the **next** step: `y_up = (ret.shift(-1) > 0)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db94072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat['y_up'] = (df_feat['ret'].shift(-1) > 0).astype(int)\n",
    "df_feat = df_feat.dropna()\n",
    "features = ['lag_1','lag_5','roll_mean_5','roll_std_5','momentum_5','zscore_5']\n",
    "X = df_feat[features].values\n",
    "y = df_feat['y_up'].values\n",
    "df_feat[['ret']+features+['y_up']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb955f35",
   "metadata": {},
   "source": [
    "## 4) Split (Time‑aware)\n",
    "We use a **holdout** (last 25%) and also a **TimeSeriesSplit** CV for robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c239f480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holdout split (last 25%)\n",
    "split_idx = int(len(df_feat) * 0.75)\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "dates_train = df_feat.index[:split_idx]\n",
    "dates_test  = df_feat.index[split_idx:]\n",
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89efb95",
   "metadata": {},
   "source": [
    "## 5) Pipeline (Scaler → LogisticRegression)\n",
    "This keeps preprocessing and model bundled and avoids leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd8e136",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression(max_iter=1000))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7420afa5",
   "metadata": {},
   "source": [
    "## 6) Fit, Predict, Evaluate\n",
    "We report accuracy, precision, recall, F1, a confusion matrix, and predicted class over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d799b339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit on train, evaluate on holdout\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "report = classification_report_df(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "# Save metrics\n",
    "save_df(report, 'data/processed/stage10b_holdout_classification_metrics.csv')\n",
    "\n",
    "# Confusion matrix plot\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "plot_confusion_matrix(y_test, y_pred, ax=ax, title=\"Holdout Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(project_path('data/processed/stage10b_confusion_matrix.png'))\n",
    "plt.show()\n",
    "\n",
    "# Prediction-over-time plot\n",
    "fig, ax = plt.subplots(figsize=(9,3.5))\n",
    "ax.plot(dates_test, y_test, label='True (Up=1)', linewidth=1)\n",
    "ax.plot(dates_test, y_pred, label='Pred (Up=1)', linewidth=1)\n",
    "ax.set_title(\"Next‑Step Direction: True vs Predicted (Holdout)\")\n",
    "ax.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(project_path('data/processed/stage10b_true_vs_pred.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785b5ca5",
   "metadata": {},
   "source": [
    "### Optional: TimeSeriesSplit cross‑validation (sanity check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff2af66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import numpy as np\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "scores = []\n",
    "for tr_idx, va_idx in tscv.split(X_train):\n",
    "    X_tr, X_va = X_train[tr_idx], X_train[va_idx]\n",
    "    y_tr, y_va = y_train[tr_idx], y_train[va_idx]\n",
    "    pipe.fit(X_tr, y_tr)\n",
    "    scores.append(f1_score(y_va, pipe.predict(X_va)))\n",
    "print(\"TimeSeriesSplit F1 scores:\", np.round(scores,3), \" | mean =\", np.mean(scores).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da461dd1",
   "metadata": {},
   "source": [
    "## 7) Interpretation\n",
    "- **What worked:** Lags and short rolling stats captured weak autocorrelation; the logistic model learns a slight edge.\n",
    "- **What failed:** Signal is small in synthetic data; performance is modest and may be noisy.\n",
    "- **Assumptions at risk:** Stationarity and stable decision boundary. Real markets shift; features may drift. Use **walk‑forward validation**, recalibration, and richer features (longer windows, macro/volatility states)."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
